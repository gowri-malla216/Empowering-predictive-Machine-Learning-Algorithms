{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5lqjWo8RlFQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('./sample_data/usa_real_estate_dataset.csv')\n",
        "\n",
        "data = data.drop(['prev_sold_date'], axis=1)\n",
        "\n",
        "categorical_columns = ['status', 'city', 'state']\n",
        "for column in categorical_columns:\n",
        "    data[column] = data[column].astype('category').cat.codes\n",
        "\n",
        "data = data.dropna(subset=['price'])\n",
        "data = data[np.isfinite(data['price'])]\n",
        "\n",
        "data = data[(data['price'] >= 2000) ]\n",
        "data['price'] += 1\n",
        "\n",
        "scale_factor = 1\n",
        "\n",
        "data['log_price'] = np.log(data['price']) * scale_factor\n",
        "features_to_drop = ['price','log_price']\n",
        "\n",
        "X = data.drop(features_to_drop, axis=1)\n",
        "y = data['log_price']\n",
        "\n",
        "for i in X.columns:\n",
        "    data = data[np.isfinite(data[i])]\n",
        "\n",
        "features_to_drop = ['price','log_price']\n",
        "X = data.drop(features_to_drop, axis=1)\n",
        "y = data['log_price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train,y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print(f'r2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "G2q0wjjTRnJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title('Actual vs Predicted')"
      ],
      "metadata": {
        "id": "xkLSd8VwRpL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [10,15,17,20],\n",
        "    'min_samples_split': [120,130, 200, 300],\n",
        "    'min_samples_leaf': [120,130, 200, 300]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring='r2')\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "cv_results = grid_search.cv_results_\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "\n",
        "axs[0].plot(param_grid['max_depth'], cv_results['mean_test_score'][::len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf'])], marker='o')\n",
        "axs[0].set_xlabel('Max Depth')\n",
        "axs[0].set_ylabel('Mean Test Score (Negative MSE)')\n",
        "axs[0].set_title('Effect of Max Depth')\n",
        "\n",
        "axs[1].plot(param_grid['min_samples_split'], cv_results['mean_test_score'][:len(param_grid['min_samples_split'])], marker='o')\n",
        "axs[1].set_xlabel('Min Samples Split')\n",
        "axs[1].set_title('Effect of Min Samples Split')\n",
        "\n",
        "axs[2].plot(param_grid['min_samples_leaf'], cv_results['mean_test_score'][0:len(param_grid['min_samples_leaf'])], marker='o')\n",
        "axs[2].set_xlabel('Min Samples Leaf')\n",
        "axs[2].set_title('Effect of Min Samples Leaf')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3BNE71kJRrFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(f'Best parameters: {grid_search.best_params_}')\n",
        "print(f'Best score (r2): {grid_search.best_score_:.2f}')"
      ],
      "metadata": {
        "id": "KYFmAdGgRwHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccp_path = best_model.cost_complexity_pruning_path(X_train, y_train)\n",
        "alphas, impurities = ccp_path['ccp_alphas'], ccp_path['impurities']\n",
        "\n",
        "trees = []\n",
        "for alpha in alphas:\n",
        "    tree = DecisionTreeRegressor(random_state=42, ccp_alpha=alpha)\n",
        "    tree.fit(X_train, y_train)\n",
        "    trees.append(tree)\n",
        "errors = []\n",
        "for tree in trees:\n",
        "    y_pred = tree.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    errors.append(mse)"
      ],
      "metadata": {
        "id": "KE357jhLRySI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor(**best_params_, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred = tree.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print(f'r2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "Ogq8hGDIR0qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title('Actual vs Predicted')"
      ],
      "metadata": {
        "id": "RAZgi46fR3zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(alphas, errors)\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Alpha vs. Mean Squared Error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EshUbSCdR56F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(best_model, X, y, cv=kf, scoring='neg_mean_squared_error')"
      ],
      "metadata": {
        "id": "Ym5-T1z0R6pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error_scores = -scores\n",
        "print(f'mean_squared_error scores: {mean_squared_error_scores}')\n",
        "mean_mean_squared_error = np.mean(mean_squared_error_scores)\n",
        "std_mean_squared_error = np.std(mean_squared_error_scores)\n",
        "\n",
        "print(f'Mean MSE: {mean_mean_squared_error:.4f}')\n",
        "print(f'Standard Deviation of MSE: {std_mean_squared_error:.4f}')\n",
        "\n",
        "mean_squared_error_scores = np.sqrt(mean_squared_error_scores)\n",
        "print(f'Mean RMSE: {np.mean(mean_squared_error_scores):.4f}')\n",
        "print(f'Standard Deviation of RMSE: {np.std(mean_squared_error_scores):.4f}')\n",
        "\n",
        "\n",
        "scores = cross_val_score(best_model, X, y, cv=kf, scoring='r2')\n",
        "\n",
        "r2_scores = scores\n",
        "print(f'R2 scores: {r2_scores}')\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "std_r2 = np.std(r2_scores)\n",
        "\n",
        "print(f'Mean r2: {mean_r2:.2f}')\n",
        "print(f'Standard Deviation of r2: {std_r2:.4f}')"
      ],
      "metadata": {
        "id": "PKQt9hVMR8f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "folder_path = \"sample_data/added_data\"\n",
        "\n",
        "type_zipcode_counts = pd.DataFrame(columns=['Zipcode'])\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        data = data.dropna(subset=['zipcode'])\n",
        "\n",
        "        file_type = data['type'].unique()[0]\n",
        "\n",
        "        counts = data.groupby('zipcode').size()\n",
        "\n",
        "        counts.name = file_type\n",
        "\n",
        "        type_zipcode_counts = pd.merge(type_zipcode_counts, counts, left_on='Zipcode', right_index=True, how='outer')\n",
        "\n",
        "\n",
        "type_zipcode_counts.fillna(0, inplace=True)\n",
        "type_zipcode_counts.rename(columns={'Zipcode': 'zipcode'}, inplace=True)\n",
        "\n",
        "type_zipcode_counts.to_csv(\"./sample_data/added_data/type_zipcode_counts.csv\", index=False)\n",
        "\n",
        "florida_data = pd.read_csv(\"./sample_data/usa_real_estate_data.csv\")\n",
        "merged_data = pd.merge(florida_data, type_zipcode_counts, on='zipcode', how='left')\n",
        "merged_data.to_csv(\"sample_data/merged.csv\", index=False)"
      ],
      "metadata": {
        "id": "cnFtV-uYR_1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['status', 'city', 'state']\n",
        "for column in categorical_columns:\n",
        "    merged_data[column] = data[column].astype('category').cat.codes\n",
        "\n",
        "merged_data = merged_data.dropna(subset=['price'])\n",
        "merged_data = merged_data[np.isfinite(data['price'])]\n",
        "\n",
        "merged_data = merged_data[(merged_data['price'] >= 2000) ]\n",
        "merged_data['price'] += 1\n",
        "\n",
        "scale_factor = 1\n",
        "\n",
        "merged_data['log_price'] = np.log(merged_data['price']) * scale_factor\n",
        "features_to_drop = ['price','log_price']\n",
        "\n",
        "X = merged_data.drop(features_to_drop, axis=1)\n",
        "y = merged_data['log_price']\n",
        "\n",
        "for i in X.columns:\n",
        "    merged_data = merged_data[np.isfinite(data[i])]\n",
        "\n",
        "features_to_drop = ['price','log_price']\n",
        "X = merged_data.drop(features_to_drop, axis=1)\n",
        "y = merged_data['log_price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cCf2Aw2OSCTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print(f'r2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "wIuasTd5SHBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print(f'r2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "34KuR0t1SI2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = rf_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "for feature, importance in zip(feature_names, feature_importances):\n",
        "    print(f'{feature}: {importance}')"
      ],
      "metadata": {
        "id": "uDCCZUn0SK4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(feature_names, feature_importances)\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Feature Importance using Random Forest')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cm2GxeE7SM4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.scatter(y_test,y_pred)\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title('Actual vs Predicted')"
      ],
      "metadata": {
        "id": "LZwG8eL7SOqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_trees = rf_model.estimators_\n",
        "alphas = np.linspace(0, 0.1, num=10)\n",
        "\n",
        "meaned_mean_squared_error = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    neg_mean_squared_error_scores = []\n",
        "    for tree in rf_trees:\n",
        "        pruned_tree = DecisionTreeRegressor(random_state=42)\n",
        "        pruned_tree = tree\n",
        "        pruned_tree.cost_complexity_pruning_path(X, y)\n",
        "        pruned_tree.ccp_alpha = alpha\n",
        "        pruned_tree = pruned_tree.fit(X, y)\n",
        "        cv_score = cross_val_score(pruned_tree, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "        neg_mean_squared_error_scores.append(cv_score.mean())\n",
        "\n",
        "    meaned_neg_mean_squared_error_score = np.mean(neg_mean_squared_error_scores)\n",
        "    meaned_mean_squared_error_score = -meaned_neg_mean_squared_error_score\n",
        "    meaned_mean_squared_error.append(meaned_mean_squared_error_score)\n",
        "\n",
        "optimal_alpha = alphas[np.argmax(meaned_mean_squared_error)]\n",
        "\n",
        "print(f'Optimal alpha value: {optimal_alpha:.4f}')\n"
      ],
      "metadata": {
        "id": "5GkIwThqSRf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, tree in enumerate(rf_trees):\n",
        "    tree.ccp_alpha = optimal_alpha\n",
        "    tree.fit(X_train, y_train)\n",
        "    rf_model.estimators_[i] = tree"
      ],
      "metadata": {
        "id": "KCluo_GmSTmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print(f'r2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "jgmBsrVqSVqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R2 Score: {r2}')\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "tFnmIW7tSXuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}